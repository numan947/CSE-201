{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bank-additional-full.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataY=data[data.y=='yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataN=data[data.y=='no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle2(df, n=1, axis=0):     \n",
    "       for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFinalData=pd.concat([myDataN.sample(n=4444,replace=False,random_state=43),myDataY])\n",
    "myFinalData = myFinalData.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "tmpHolder=myFinalData.dtypes\n",
    "\n",
    "#converting to categorical type\n",
    "for i in range(len(tmpHolder)):\n",
    "    if(tmpHolder[i]=='object'):\n",
    "        myFinalData[tmpHolder.index[i]]=myFinalData[tmpHolder.index[i]].astype('category')\n",
    "myFinalData=myFinalData.drop(columns=['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet,testSet=train_test_split(myFinalData,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs):\n",
    "    return sum([-prob*np.log2(prob) for prob in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_list(list_item):\n",
    "    #print(list_item)\n",
    "    from collections import Counter\n",
    "    mp = Counter(x for x in list_item)\n",
    "    total=1.0*len(list_item)\n",
    "\n",
    "    probs = [tt/total for tt in mp.values()]\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_cat(df, split_attribute_name, target_attribute_name):\n",
    "    \n",
    "    dfTmp=df.copy(deep=True)\n",
    "    #Split\n",
    "    df_split = dfTmp.groupby(split_attribute_name)\n",
    "    \n",
    "    dct={}\n",
    "    \n",
    "    nrows=len(dfTmp.index)*1.0\n",
    "    \n",
    "    #Merge\n",
    "    for name,group in df_split:\n",
    "    #   print(name,entropy_categorical(np.array(group['y'],dtype=pd.Series)),len(group)/nrows)\n",
    "        dct[name]=[entropy_list(np.array(group[target_attribute_name],dtype=pd.Series)),len(group)/nrows]\n",
    "\n",
    "    dd = pd.DataFrame(dct)\n",
    "    dd=dd.T\n",
    "    dd.columns=['Entropy','ObsProp']\n",
    "    \n",
    "    #print(dd)\n",
    "    \n",
    "    #Gain\n",
    "    \n",
    "    new_entropy = sum( dd['Entropy'] *dd['ObsProp'] )\n",
    "    \n",
    "    \n",
    "    old_entropy = entropy_list(dfTmp[target_attribute_name])\n",
    "    \n",
    "    \n",
    "    return old_entropy-new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03224206832308152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_cat(trainSet,'job','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_num(df,split_attribute_name,target_attribute_name):\n",
    "    dfTemp=df.copy(deep=True)\n",
    "    \n",
    "    dfTemp=dfTemp.sort_values(split_attribute_name)\n",
    "    \n",
    "    split_points=dfTemp[split_attribute_name].unique()\n",
    "    #print(dfTemp[split_attribute_name].unique())\n",
    "    \n",
    "    gains={}\n",
    "    \n",
    "    cols=list(dfTemp.columns)\n",
    "    \n",
    "    #print(cols)\n",
    "    \n",
    "    \n",
    "    pos=cols.index(split_attribute_name)\n",
    "    #print(pos)\n",
    "    \n",
    "    parent_entr=entropy_list(dfTemp[target_attribute_name])\n",
    "    \n",
    "    \n",
    "    best_split=-np.inf\n",
    "    best_gain=-np.inf\n",
    "    \n",
    "    \n",
    "    for split_point in split_points:\n",
    "        \n",
    "        subset_df1 = dfTemp[dfTemp[split_attribute_name] <= split_point]\n",
    "        subset_df2 = dfTemp[dfTemp[split_attribute_name] > split_point]\n",
    "        \n",
    "        s1_entr=entropy_list(subset_df1[target_attribute_name])\n",
    "        s2_entr=entropy_list(subset_df2[target_attribute_name])\n",
    "            \n",
    "        child_entr=s1_entr*len(subset_df1.index)+s2_entr*len(subset_df2.index)\n",
    "        child_entr/=len(dfTemp.index)\n",
    "        tmpGain=parent_entr-child_entr\n",
    "        \n",
    "        if((best_gain==-np.inf and best_split==-np.inf)or(tmpGain>best_gain)):\n",
    "            best_split=split_point\n",
    "            best_gain=tmpGain\n",
    "        #print(split_point,tmpGain)\n",
    "    \n",
    "    return best_gain,best_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14178751522417155, -1.1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_num(myFinalData,'emp.var.rate','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self,attr_name,kind):\n",
    "        self.attr_name=attr_name\n",
    "        self.kind=kind\n",
    "    \n",
    "    def setThreshold(self,threshold):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.threshold=threshold\n",
    "        else:\n",
    "            raise ValueError(\"Threshold can't be set for categorical variable\")\n",
    "    \n",
    "    def setLessThanEq(self,cls):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.less_than_eq_class=cls\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for categorical variable\")\n",
    "    \n",
    "    def setGreaterThan(self,cls):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.greater_than_class=cls\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for categorical variable\")\n",
    "    \n",
    "    def setLevelClassMap(self,levelClassMap):\n",
    "        if(self.kind=='categorical'):\n",
    "            self.levelClassMap=levelClassMap\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for numeric variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCategorical(df,attr):\n",
    "    if(df[attr].dtype.name=='category'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def DecisionStump(mydf,all_attr,target_attr,default_class=None):\n",
    "    df=mydf.copy(deep=True)\n",
    "    \n",
    "    gains=[] \n",
    "    for attr in all_attr:\n",
    "        if(isCategorical(df,attr)):\n",
    "            ig = information_gain_cat(df=df,split_attribute_name=attr,target_attribute_name=target_attr)\n",
    "            splt=-np.inf\n",
    "        else:\n",
    "            ig,splt=information_gain_num(df=df,split_attribute_name=attr,target_attribute_name=target_attr)\n",
    "        gains.append((ig,splt))\n",
    "        \n",
    "    mx_gain=max(gains,key=itemgetter(0))[0]\n",
    "    \n",
    "    #print(mx_gain)\n",
    "    \n",
    "    mx_gain_idx=-1\n",
    "    for i in range(len(gains)):\n",
    "        if(gains[i][0]==mx_gain):\n",
    "            mx_gain_idx=i\n",
    "            break\n",
    "#     print(gains)\n",
    "#     print(all_attr[mx_gain_idx])\n",
    "    \n",
    "    mx_gain_attr=all_attr[mx_gain_idx]\n",
    "    \n",
    "  #  print(mx_gain_attr)\n",
    "    \n",
    "    #splitting for Numeric Attributes\n",
    "    if(not(isCategorical(df,mx_gain_attr))):\n",
    "        thresh=gains[mx_gain_idx][1]\n",
    "        df1=df[df[mx_gain_attr]<=thresh]\n",
    "        df2=df[df[mx_gain_attr]>thresh]\n",
    "        dn=DecisionNode(mx_gain_attr,'numeric')\n",
    "        dn.setThreshold(thresh)\n",
    "        ly=df1[df1.y=='yes'].shape[0]\n",
    "        ln=df1[df1.y=='no'].shape[0]\n",
    "        \n",
    "        if(ly>=ln):\n",
    "            dn.setLessThanEq('yes')\n",
    "        else:\n",
    "            dn.setLessThanEq('no')\n",
    "        gy=df2[df2.y=='yes'].shape[0]\n",
    "        gn=df2[df2.y=='no'].shape[0]\n",
    "        if(gy>=gn):\n",
    "            dn.setGreaterThan('yes')\n",
    "        else:\n",
    "            dn.setGreaterThan('no')\n",
    "        \n",
    "        return dn\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        dn=DecisionNode(mx_gain_attr,'categorical')\n",
    "        df_split = df.groupby(mx_gain_attr)\n",
    "\n",
    "        dct={}\n",
    "        for name,group in df_split:\n",
    "            y=group[group.y=='yes'].shape[0]\n",
    "            n=group[group.y=='no'].shape[0]\n",
    "            if(y>=n):\n",
    "                dct[name]='yes'\n",
    "            else:\n",
    "                dct[name]='no'\n",
    "            #print(name,group[group.y=='yes'].shape[0],group[group.y=='no'].shape[0])\n",
    "            \n",
    "        print(dct)\n",
    "            #dct[name]=[entropy_list(np.array(group[target_attribute_name],dtype=pd.Series)),len(group)/nrows]\n",
    "        dn.setLevelClassMap(dct)\n",
    "        return dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(df,h):\n",
    "    attr=h.attr_name\n",
    "    dataPoints=df[attr]\n",
    "    y_pred=[]\n",
    "    if(h.kind=='categorical'):\n",
    "        dct=h.levelClassMap\n",
    "        y_pred= [dct[x] for x in dataPoints]\n",
    "    else:\n",
    "        thresh=h.threshold\n",
    "        for x in dataPoints:\n",
    "            if(x<=thresh):\n",
    "                y_pred.append(h.less_than_eq_class)\n",
    "            else:\n",
    "                y_pred.append(h.greater_than_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {yes,no}==>{+1,-1}\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self,k,target_attr):\n",
    "        self.hyp= []\n",
    "        self.hyp_wgt = []\n",
    "        self.k=k\n",
    "        self.target_attr=target_attr\n",
    "        \n",
    "    def train(self,df):\n",
    "        \n",
    "        sampN, _ = df.shape\n",
    "        samp_wgt = np.ones(sampN) / sampN\n",
    "        \n",
    "        ktmp=self.k\n",
    "        \n",
    "        \n",
    "        while ktmp>0:\n",
    "          #  print(samp_wgt)\n",
    "            \n",
    "            sampled_data=df.sample(n=sampN,replace=True,weights=samp_wgt,random_state=43)\n",
    "            cols=list(sampled_data.columns)\n",
    "            cols.remove(self.target_attr)\n",
    "            \n",
    "            h=DecisionStump(mydf=sampled_data,all_attr=cols,target_attr=self.target_attr)\n",
    "            \n",
    "            \n",
    "#             h = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "#             h.fit(X, y, sample_weight=samp_wgt)\n",
    "#             pred = h.predict(X)\n",
    "            \n",
    "            y_pred=Predict(df=sampled_data,h=h)\n",
    "            y_actual=np.array(sampled_data[self.target_attr],dtype=pd.Series)\n",
    "            \n",
    "            \n",
    "            yy_pred=[]\n",
    "            yy_actual=[]\n",
    "            \n",
    "            for i in range(len(y_actual)):\n",
    "                if(y_pred[i]=='yes'):\n",
    "                    yy_pred.append(1)\n",
    "                else:\n",
    "                    yy_pred.append(-1)\n",
    "                if(y_actual[i]=='yes'):\n",
    "                    yy_actual.append(1)\n",
    "                else:\n",
    "                    yy_actual.append(-1)\n",
    "    \n",
    "    \n",
    "            misses=[]\n",
    "            for i in range(len(yy_actual)):\n",
    "                if(yy_actual[i]!=yy_pred[i]):\n",
    "                    misses.append(np.float64(1))\n",
    "                else:\n",
    "                    misses.append(np.float64(0))\n",
    "        \n",
    "          #  print(misses)\n",
    "    \n",
    "            eps = np.dot(samp_wgt,misses)# samp_wgt.dot(yy_pred != yy_actual)\n",
    "            \n",
    "#             print(type(eps))\n",
    "#             print(eps)\n",
    "            \n",
    "            if(eps>0.5):\n",
    "                continue\n",
    "            \n",
    "            alpha = (np.log(1 - eps) - np.log(eps)) / 2.0\n",
    "            \n",
    "#             print(type(samp_wgt[0]))\n",
    "#             print(type(alpha))\n",
    "#             print(type(yy_actual))\n",
    "#             print(type(yy_pred))\n",
    "            \n",
    "            \n",
    "            yy_actual=np.array(yy_actual,dtype=np.float64)\n",
    "            yy_pred=np.array(yy_pred,dtype=np.float64)\n",
    "            \n",
    "            samp_wgt = samp_wgt * np.exp(- alpha * yy_actual * yy_pred)\n",
    "   #         print(\"after \",samp_wgt)\n",
    "\n",
    "\n",
    "#             for i in range(len(samp_wgt)):\n",
    "#               #  print(t, \" th samp_wgt \",samp_wgt[i])\n",
    "#                 if(math.isnan(samp_wgt[i])):\n",
    "#                     samp_wgt[i]=0\n",
    "            #print(max(samp_wgt))\n",
    "            #print(\"HELLOWORLD \",np.sum(samp_wgt))\n",
    "            samp_wgt = samp_wgt / samp_wgt.sum()\n",
    "            samp_wgt=np.array(samp_wgt,dtype=pd.Series)\n",
    "            #print(\"HELLOWORLD \",samp_wgt.sum())\n",
    "            \n",
    "#             print(t,\"th iteration\")\n",
    "#             print(samp_wgt)\n",
    "#             print(np.sum(samp_wgt,dtype=np.float128))\n",
    "#             print()\n",
    "            \n",
    "            self.hyp.append(h)\n",
    "            self.hyp_wgt.append(alpha)\n",
    "            ktmp-=1\n",
    "        return samp_wgt\n",
    "    \n",
    "    def test(self,X):\n",
    "        \n",
    "        sampN, _ = X.shape\n",
    "        samp_wgt = np.ones(sampN) / sampN\n",
    "        y=np.zeros(sampN)\n",
    "        \n",
    "        \n",
    "        for (h, alpha) in zip(self.hyp, self.hyp_wgt):\n",
    "            y_pred=Predict(df=X,h=h)\n",
    "            \n",
    "            yy_pred=[]\n",
    "            for i in range(len(y_pred)):\n",
    "                if(y_pred[i]=='yes'):\n",
    "                    yy_pred.append(np.float64(1))\n",
    "                else:\n",
    "                    yy_pred.append(np.float64(-1))\n",
    "            \n",
    "#             print(type(y))\n",
    "#             print(type(alpha))\n",
    "#             print(type(yy_pred))\n",
    "            yy_pred=np.array(yy_pred,dtype=np.float64)\n",
    "            \n",
    "            y = y + alpha * yy_pred\n",
    "        \n",
    "#         print(y)\n",
    "        \n",
    "        y = np.sign(y)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(df,target,k=3,K=5):\n",
    "    \n",
    "    \n",
    "    kf=KFold(n_splits=k)\n",
    "    \n",
    "    models=[]\n",
    "    f1_scores=[]\n",
    "    \n",
    "    best_score=None\n",
    "    best_model=None\n",
    "    \n",
    "    \n",
    "    #print(kf.get_n_splits(df))\n",
    "    for train,test in kf.split(df):\n",
    "        \n",
    "        dftr=df.iloc[train]\n",
    "        dfts=df.iloc[test]\n",
    "        \n",
    "        ada=AdaBoost(k=K,target_attr=target)\n",
    "        \n",
    "        ada.train(df=dftr)\n",
    "        y_pred=ada.test(dfts)\n",
    "        y_true=np.array(dfts[target],dtype=pd.Series)\n",
    "        \n",
    "       # print(y_true)\n",
    "        \n",
    "        yy_true=[]\n",
    "        for i in range(len(y_true)):\n",
    "            if(y_true[i]=='yes'):\n",
    "                yy_true.append(1)\n",
    "            else:\n",
    "                yy_true.append(-1)\n",
    "                \n",
    "                \n",
    "        fs=f1_score(y_true=yy_true,y_pred=y_pred)\n",
    "        \n",
    "        models.append(ada)\n",
    "        f1_scores.append(fs)\n",
    "        \n",
    "        if(best_score==None or (fs>best_score)):\n",
    "            best_model=ada\n",
    "            best_score=fs\n",
    "        \n",
    "        print(fs)\n",
    "    \n",
    "    print(\"AVG: \",sum(f1_scores)/len(f1_scores))\n",
    "    \n",
    "    return best_model,best_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRYING fold =  5  and Round =  5\n",
      "\n",
      "0.6275659824046921\n",
      "0.6264626462646264\n",
      "0.6076421248835041\n",
      "0.5842055185537584\n",
      "0.6074498567335245\n",
      "AVG:  0.6106652257680211\n",
      "\n",
      "TRYING fold =  5  and Round =  10\n",
      "\n",
      "0.6275659824046921\n",
      "0.6264626462646264\n",
      "0.6076421248835041\n",
      "0.5842055185537584\n",
      "0.6074498567335245\n",
      "AVG:  0.6106652257680211\n",
      "\n",
      "TRYING fold =  5  and Round =  20\n",
      "\n",
      "0.6275659824046921\n",
      "0.6264626462646264\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-c1af6bc4c56b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TRYING fold = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" and Round = \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-4f8fe214255e>\u001b[0m in \u001b[0;36mcrossValidation\u001b[0;34m(df, target, k, K)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mada\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAdaBoost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdftr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mada\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-7fcfd89b25b3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, df)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDecisionStump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmydf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mall_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_attr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-f265c9a26f69>\u001b[0m in \u001b[0;36mDecisionStump\u001b[0;34m(mydf, all_attr, target_attr, default_class)\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0msplt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minformation_gain_num\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplit_attribute_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_attribute_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mgains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msplt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-f166749dd2a9>\u001b[0m in \u001b[0;36minformation_gain_num\u001b[0;34m(df, split_attribute_name, target_attribute_name)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msplit_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_points\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0msubset_df1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfTemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfTemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_attribute_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0msplit_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0msubset_df2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdfTemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdfTemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_attribute_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0msplit_point\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2173\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2175\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take\u001b[0;34m(self, indices, axis, convert, is_copy)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         new_data = self._data.take(indices,\n\u001b[1;32m   2149\u001b[0m                                    \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m                                    verify=True)\n\u001b[0m\u001b[1;32m   2151\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   4262\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4263\u001b[0m         return self.reindex_indexer(new_axis=new_labels, indexer=indexer,\n\u001b[0;32m-> 4264\u001b[0;31m                                     axis=axis, allow_dups=True)\n\u001b[0m\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy)\u001b[0m\n\u001b[1;32m   4148\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4149\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4150\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4148\u001b[0m             new_blocks = [blk.take_nd(indexer, axis=axis, fill_tuple=(\n\u001b[1;32m   4149\u001b[0m                 fill_value if fill_value is not None else blk.fill_value,))\n\u001b[0;32m-> 4150\u001b[0;31m                 for blk in self.blocks]\n\u001b[0m\u001b[1;32m   4151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m         \u001b[0mnew_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mfill_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try_fold=[5,10,20]\n",
    "try_round=[5,10,20]\n",
    "\n",
    "for i in try_fold:\n",
    "    for j in try_round:\n",
    "        print(\"TRYING fold = \",i,\" and Round = \",j)\n",
    "        print()\n",
    "        m,s=crossValidation(df=trainSet,k=i,K=j,target='y')\n",
    "        print()\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoost(k=10,target_attr='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada.train(df=trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=ada.test(X=testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_act=np.array(testSet['y'],dtype=pd.Series)\n",
    "yy_act=[]\n",
    "for i in range(len(y_act)):\n",
    "    if(y_act[i]=='yes'):\n",
    "        yy_act.append(1)\n",
    "    else:\n",
    "        yy_act.append(-1)\n",
    "\n",
    "f1_score(y_pred=y_pred,y_true=yy_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "round = 1 crossvalidation = 5\n",
      "0.6275659824046921\n",
      "0.6264626462646264\n",
      "0.6076421248835041\n",
      "0.5842055185537584\n",
      "0.6074498567335245\n",
      "AVG:  0.6106652257680211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<__main__.AdaBoost at 0x7fc8fb0da710>, 0.6275659824046921)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"round = 1 crossvalidation = 5\")\n",
    "crossValidation(K=1,df=trainSet,k=5,target='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"round = 30 crossvalidation = 5\")\n",
    "crossValidation(K=30,df=trainSet,k=5,target='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
