{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bank-additional-full.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataY=data[data.y=='yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataN=data[data.y=='no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle2(df, n=1, axis=0):     \n",
    "       for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFinalData=pd.concat([myDataN.sample(n=4444,replace=False,),myDataY])\n",
    "myFinalData = myFinalData.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "tmpHolder=myFinalData.dtypes\n",
    "\n",
    "#converting to categorical type\n",
    "for i in range(len(tmpHolder)):\n",
    "    if(tmpHolder[i]=='object'):\n",
    "        myFinalData[tmpHolder.index[i]]=myFinalData[tmpHolder.index[i]].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet,testSet=train_test_split(myFinalData,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs):\n",
    "    return sum([-prob*np.log2(prob) for prob in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_list(list_item):\n",
    "    #print(list_item)\n",
    "    from collections import Counter\n",
    "    mp = Counter(x for x in list_item)\n",
    "    total=1.0*len(list_item)\n",
    "\n",
    "    probs = [tt/total for tt in mp.values()]\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_cat(df, split_attribute_name, target_attribute_name):\n",
    "    \n",
    "    dfTmp=df.copy(deep=True)\n",
    "    #Split\n",
    "    df_split = dfTmp.groupby(split_attribute_name)\n",
    "    \n",
    "    dct={}\n",
    "    \n",
    "    nrows=len(dfTmp.index)*1.0\n",
    "    \n",
    "    #Merge\n",
    "    for name,group in df_split:\n",
    "    #   print(name,entropy_categorical(np.array(group['y'],dtype=pd.Series)),len(group)/nrows)\n",
    "        dct[name]=[entropy_list(np.array(group[target_attribute_name],dtype=pd.Series)),len(group)/nrows]\n",
    "\n",
    "    dd = pd.DataFrame(dct)\n",
    "    dd=dd.T\n",
    "    dd.columns=['Entropy','ObsProp']\n",
    "    \n",
    "    #print(dd)\n",
    "    \n",
    "    #Gain\n",
    "    \n",
    "    new_entropy = sum( dd['Entropy'] *dd['ObsProp'] )\n",
    "    \n",
    "    \n",
    "    old_entropy = entropy_list(dfTmp[target_attribute_name])\n",
    "    \n",
    "    \n",
    "    return old_entropy-new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03589354511714926"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_cat(trainSet,'job','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_num(df,split_attribute_name,target_attribute_name):\n",
    "    dfTemp=df.copy(deep=True)\n",
    "    \n",
    "    dfTemp=dfTemp.sort_values(split_attribute_name)\n",
    "    \n",
    "    split_points=dfTemp[split_attribute_name].unique()\n",
    "    #print(dfTemp[split_attribute_name].unique())\n",
    "    \n",
    "    gains={}\n",
    "    \n",
    "    cols=list(dfTemp.columns)\n",
    "    \n",
    "    #print(cols)\n",
    "    \n",
    "    \n",
    "    pos=cols.index(split_attribute_name)\n",
    "    #print(pos)\n",
    "    \n",
    "    parent_entr=entropy_list(dfTemp[target_attribute_name])\n",
    "    \n",
    "    \n",
    "    best_split=-np.inf\n",
    "    best_gain=-np.inf\n",
    "    \n",
    "    \n",
    "    for split_point in split_points:\n",
    "        \n",
    "        subset_df1 = dfTemp[dfTemp[split_attribute_name] <= split_point]\n",
    "        subset_df2 = dfTemp[dfTemp[split_attribute_name] > split_point]\n",
    "        \n",
    "        s1_entr=entropy_list(subset_df1[target_attribute_name])\n",
    "        s2_entr=entropy_list(subset_df2[target_attribute_name])\n",
    "            \n",
    "        child_entr=s1_entr*len(subset_df1.index)+s2_entr*len(subset_df2.index)\n",
    "        child_entr/=len(dfTemp.index)\n",
    "        tmpGain=parent_entr-child_entr\n",
    "        \n",
    "        if((best_gain==-np.inf and best_split==-np.inf)or(tmpGain>best_gain)):\n",
    "            best_split=split_point\n",
    "            best_gain=tmpGain\n",
    "        #print(split_point,tmpGain)\n",
    "    \n",
    "    return best_gain,best_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.13651874166436118, -1.1)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_num(myFinalData,'emp.var.rate','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self,attr_name,kind):\n",
    "        self.attr_name=attr_name\n",
    "        self.kind=kind\n",
    "    \n",
    "    def setThreshold(self,threshold):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.threshold=threshold\n",
    "        else:\n",
    "            raise ValueError(\"Threshold can't be set for categorical variable\")\n",
    "    \n",
    "    def setLessThanEq(self,cls):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.less_than_eq_class=cls\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for categorical variable\")\n",
    "    \n",
    "    def setGreaterThan(self,cls):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.greater_than_class=cls\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for categorical variable\")\n",
    "    \n",
    "    def setLevelClassMap(self,levelClassMap):\n",
    "        if(self.kind=='categorical'):\n",
    "            self.levelClassMap=levelClassMap\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for numeric variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCategorical(df,attr):\n",
    "    if(df[attr].dtype.name=='category'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def DecisionStump(mydf,all_attr,target_attr,default_class=None):\n",
    "    df=mydf.copy(deep=True)\n",
    "    \n",
    "    gains=[] \n",
    "    for attr in all_attr:\n",
    "        if(isCategorical(df,attr)):\n",
    "            ig = information_gain_cat(df=df,split_attribute_name=attr,target_attribute_name=target_attr)\n",
    "            splt=-np.inf\n",
    "        else:\n",
    "            ig,splt=information_gain_num(df=df,split_attribute_name=attr,target_attribute_name=target_attr)\n",
    "        gains.append((ig,splt))\n",
    "        \n",
    "    mx_gain=max(gains,key=itemgetter(0))[0]\n",
    "    \n",
    "    print(mx_gain)\n",
    "    \n",
    "    mx_gain_idx=-1\n",
    "    for i in range(len(gains)):\n",
    "        if(gains[i][0]==mx_gain):\n",
    "            mx_gain_idx=i\n",
    "            break\n",
    "#     print(gains)\n",
    "#     print(all_attr[mx_gain_idx])\n",
    "    \n",
    "    mx_gain_attr=all_attr[mx_gain_idx]\n",
    "    \n",
    "    print(mx_gain_attr)\n",
    "    \n",
    "    #splitting for Numeric Attributes\n",
    "    if(not(isCategorical(df,mx_gain_attr))):\n",
    "        thresh=gains[mx_gain_idx][1]\n",
    "        df1=df[df[mx_gain_attr]<=thresh]\n",
    "        df2=df[df[mx_gain_attr]>thresh]\n",
    "        dn=DecisionNode(mx_gain_attr,'numeric')\n",
    "        dn.setThreshold(thresh)\n",
    "        ly=df1[df1.y=='yes'].shape[0]\n",
    "        ln=df1[df1.y=='no'].shape[0]\n",
    "        \n",
    "        if(ly>=ln):\n",
    "            dn.setLessThanEq('yes')\n",
    "        else:\n",
    "            dn.setLessThanEq('no')\n",
    "        gy=df2[df2.y=='yes'].shape[0]\n",
    "        gn=df2[df2.y=='no'].shape[0]\n",
    "        if(gy>=gn):\n",
    "            dn.setGreaterThan('yes')\n",
    "        else:\n",
    "            dn.setGreaterThan('no')\n",
    "        \n",
    "        return dn\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        dn=DecisionNode(mx_gain_attr,'categorical')\n",
    "        df_split = df.groupby(mx_gain_attr)\n",
    "\n",
    "        dct={}\n",
    "        for name,group in df_split:\n",
    "            y=group[group.y=='yes'].shape[0]\n",
    "            n=group[group.y=='no'].shape[0]\n",
    "            if(y>=n):\n",
    "                dct[name]='yes'\n",
    "            else:\n",
    "                dct[name]='no'\n",
    "            #print(name,group[group.y=='yes'].shape[0],group[group.y=='no'].shape[0])\n",
    "            \n",
    "        print(dct)\n",
    "            #dct[name]=[entropy_list(np.array(group[target_attribute_name],dtype=pd.Series)),len(group)/nrows]\n",
    "        dn.setLevelClassMap(dct)\n",
    "        return dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(df,h):\n",
    "    attr=h.attr_name\n",
    "    dataPoints=df[attr]\n",
    "    y_pred=[]\n",
    "    if(h.kind=='categorical'):\n",
    "        dct=h.levelClassMap\n",
    "        y_pred= [dct[x] for x in dataPoints]\n",
    "    else:\n",
    "        thresh=h.threshold\n",
    "        for x in dataPoints:\n",
    "            if(x<=thresh):\n",
    "                y_pred.append(h.less_than_eq_class)\n",
    "            else:\n",
    "                y_pred.append(h.greate_than_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_Categorical=trainSet[['age','job','marital','education','default','housing','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcolumns=list(Test_Categorical.columns)\n",
    "catcolumns.remove('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03589354511714926\n",
      "job\n",
      "{'admin.': 'yes', 'blue-collar': 'no', 'entrepreneur': 'no', 'housemaid': 'no', 'management': 'yes', 'retired': 'yes', 'self-employed': 'yes', 'services': 'no', 'student': 'yes', 'technician': 'no', 'unemployed': 'yes', 'unknown': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "h=DecisionStump(trainSet,catcolumns,'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=Predict(testSet,h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act=testSet['y']\n",
    "y_act=np.array(y_act,dtype=pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298   2271\n",
      "accuracy  57.15543813298107\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in range(len(y_act)):\n",
    "    if(y_act[i]==y_pred[i]):\n",
    "        cnt+=1\n",
    "\n",
    "print(cnt,\" \",len(y_pred))\n",
    "print(\"accuracy \",100.0*cnt/len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ID3(df,target_attr,all_attr,depth_available,default_class=None):\n",
    "    \n",
    "    from collections import Counter\n",
    "    cnt=Counter(x for x in df[target_attr])\n",
    "    \n",
    "    #splitting is done\n",
    "    if(len(cnt)==1):\n",
    "        return list(cnt.keys())[0]\n",
    "    \n",
    "    elif df.empty or (not(all_attr)) or not(depth_available):\n",
    "        return default_class\n",
    "    else:\n",
    "        #default value for next recursive call\n",
    "        \n",
    "       # print(max(cnt.values()))\n",
    "        #print(cnt.values())\n",
    "        mx_indx = list(cnt.values()).index(max(cnt.values()))\n",
    "        default_class=list(cnt.keys())[mx_indx]\n",
    "        \n",
    "        #print(\"default class \",depth_available,\" \",mx_indx,\" \",default_class)\n",
    "        \n",
    "        #choose best attribute to split on\n",
    "        gains =[information_gain(df,attr,target_attr) for attr in all_attr]\n",
    "        indx_mx_gain = gains.index(max(gains))\n",
    "        best_attr=all_attr[indx_mx_gain]\n",
    "        \n",
    "        \n",
    "        #empty tree\n",
    "        tree={best_attr:{}}\n",
    "        rest_attr=[at for at in all_attr if at!=best_attr]\n",
    "        \n",
    "        #splitting the dataset\n",
    "        \n",
    "        for attr,data in df.groupby(best_attr):\n",
    "            subtree=ID3(data,target_attr,rest_attr,depth_available-1,default_class)\n",
    "            \n",
    "            tree[best_attr][attr]=subtree\n",
    "        \n",
    "        return tree\n",
    "\n",
    "       \n",
    "def classify(instance, tree, default=None):\n",
    "    attribute = list(tree.keys())[0]\n",
    "    \n",
    "    if instance[attribute] in tree[attribute].keys():\n",
    "        \n",
    "        result = tree[attribute][instance[attribute]]\n",
    "        \n",
    "        if isinstance(result, dict): # this is a tree, delve deeper\n",
    "            return classify(instance, result)\n",
    "        else:\n",
    "            return result # this is a label\n",
    "    else:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_attr=list(trainSet.columns)\n",
    "all_attr.remove('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSet['predicted'] =testSet.apply(classify, axis=1, args=(tree,'no') ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Accuracy is ' + str( sum(testSet['y']==testSet['predicted'] ) / (1.0*len(testSet.index)) ))\n",
    "testSet[testSet['predicted']=='yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: dataset X and labels y (in {+1, -1})\n",
    "class AdaBoost:\n",
    "    def __init__(self,num_iterations):\n",
    "        self.hyp= []\n",
    "        self.hyp_wgt = []\n",
    "        self.num_iterations=num_iterations\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def train(self,df):\n",
    "        \n",
    "        \n",
    "        sampN, _ = df.shape\n",
    "        samp_wgt = np.ones(sampN) / sampN\n",
    "        \n",
    "        for t in range(self.num_iterations):\n",
    "          #  print(samp_wgt)\n",
    "            \n",
    "            sampled_data=df.sample(n=sampN,replace=True,weights=samp_wgt)\n",
    "            \n",
    "            X=sampled_data.drop(columns=['y'])\n",
    "            y=sampled_data['y']\n",
    "        \n",
    "            \n",
    "            h = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "            h.fit(X, y, sample_weight=samp_wgt)\n",
    "            pred = h.predict(X)\n",
    "\n",
    "            eps = samp_wgt.dot(pred != y)\n",
    "            alpha = (np.log(1 - eps) - np.log(eps)) / 2\n",
    "            \n",
    "            print(eps)\n",
    "\n",
    "            samp_wgt = samp_wgt * np.exp(- alpha * y * pred)\n",
    "            samp_wgt = samp_wgt / samp_wgt.sum()\n",
    "            \n",
    "            samp_wgt=np.array(samp_wgt,dtype=pd.Series)\n",
    "\n",
    "            self.hyp.append(h)\n",
    "            self.hyp_wgt.append(alpha)\n",
    "        return samp_wgt\n",
    "    \n",
    "    def test(self,X):\n",
    "        \n",
    "        sampN, _ = X.shape\n",
    "        samp_wgt = np.ones(sampN) / sampN\n",
    "        y=np.zeros(sampN)\n",
    "        \n",
    "        \n",
    "        for (h, alpha) in zip(self.hyp, self.hyp_wgt):\n",
    "            y = y + alpha * h.predict(X)\n",
    "        \n",
    "        print(y)\n",
    "        \n",
    "        y = np.sign(y)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data2.drop(columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data2['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = AdaBoost(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw=asd.train(data2)\n",
    "sw=sw.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = asd.test(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_act = data2['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_act),len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for i in range(len(y_act)):\n",
    "    if(y_act[i]==y_pred[i]):\n",
    "        count+=1\n",
    "\n",
    "print(100*count/len(y_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true=y_act,y_pred=y_pred,average=None),f1_score(y_act, y_pred, average='weighted',sample_weight=sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = data.dtypes\n",
    "data2 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(ss)):\n",
    "    if(ss[i]=='object'):\n",
    "        print(ss[i], ss.index[i])\n",
    "        data2[ss.index[i]]=data2[ss.index[i]].astype('category')\n",
    "        data2[ss.index[i]]=data2[ss.index[i]].cat.codes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['y'] = data2['y'].map({0: -1,1: 1})\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
