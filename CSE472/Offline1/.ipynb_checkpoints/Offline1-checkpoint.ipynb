{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('bank-additional-full.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataY=data[data.y=='yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataN=data[data.y=='no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle2(df, n=1, axis=0):     \n",
    "       for _ in range(n):\n",
    "        df.apply(np.random.shuffle, axis=axis)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFinalData=pd.concat([myDataN.sample(n=4444,replace=False,),myDataY])\n",
    "myFinalData = myFinalData.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "tmpHolder=myFinalData.dtypes\n",
    "\n",
    "#converting to categorical type\n",
    "for i in range(len(tmpHolder)):\n",
    "    if(tmpHolder[i]=='object'):\n",
    "        myFinalData[tmpHolder.index[i]]=myFinalData[tmpHolder.index[i]].astype('category')\n",
    "myFinalData=myFinalData.drop(columns=['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet,testSet=train_test_split(myFinalData,test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Stump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(probs):\n",
    "    return sum([-prob*np.log2(prob) for prob in probs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_list(list_item):\n",
    "    #print(list_item)\n",
    "    from collections import Counter\n",
    "    mp = Counter(x for x in list_item)\n",
    "    total=1.0*len(list_item)\n",
    "\n",
    "    probs = [tt/total for tt in mp.values()]\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_cat(df, split_attribute_name, target_attribute_name):\n",
    "    \n",
    "    dfTmp=df.copy(deep=True)\n",
    "    #Split\n",
    "    df_split = dfTmp.groupby(split_attribute_name)\n",
    "    \n",
    "    dct={}\n",
    "    \n",
    "    nrows=len(dfTmp.index)*1.0\n",
    "    \n",
    "    #Merge\n",
    "    for name,group in df_split:\n",
    "    #   print(name,entropy_categorical(np.array(group['y'],dtype=pd.Series)),len(group)/nrows)\n",
    "        dct[name]=[entropy_list(np.array(group[target_attribute_name],dtype=pd.Series)),len(group)/nrows]\n",
    "\n",
    "    dd = pd.DataFrame(dct)\n",
    "    dd=dd.T\n",
    "    dd.columns=['Entropy','ObsProp']\n",
    "    \n",
    "    #print(dd)\n",
    "    \n",
    "    #Gain\n",
    "    \n",
    "    new_entropy = sum( dd['Entropy'] *dd['ObsProp'] )\n",
    "    \n",
    "    \n",
    "    old_entropy = entropy_list(dfTmp[target_attribute_name])\n",
    "    \n",
    "    \n",
    "    return old_entropy-new_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031088731643523104"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_cat(trainSet,'job','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain_num(df,split_attribute_name,target_attribute_name):\n",
    "    dfTemp=df.copy(deep=True)\n",
    "    \n",
    "    dfTemp=dfTemp.sort_values(split_attribute_name)\n",
    "    \n",
    "    split_points=dfTemp[split_attribute_name].unique()\n",
    "    #print(dfTemp[split_attribute_name].unique())\n",
    "    \n",
    "    gains={}\n",
    "    \n",
    "    cols=list(dfTemp.columns)\n",
    "    \n",
    "    #print(cols)\n",
    "    \n",
    "    \n",
    "    pos=cols.index(split_attribute_name)\n",
    "    #print(pos)\n",
    "    \n",
    "    parent_entr=entropy_list(dfTemp[target_attribute_name])\n",
    "    \n",
    "    \n",
    "    best_split=-np.inf\n",
    "    best_gain=-np.inf\n",
    "    \n",
    "    \n",
    "    for split_point in split_points:\n",
    "        \n",
    "        subset_df1 = dfTemp[dfTemp[split_attribute_name] <= split_point]\n",
    "        subset_df2 = dfTemp[dfTemp[split_attribute_name] > split_point]\n",
    "        \n",
    "        s1_entr=entropy_list(subset_df1[target_attribute_name])\n",
    "        s2_entr=entropy_list(subset_df2[target_attribute_name])\n",
    "            \n",
    "        child_entr=s1_entr*len(subset_df1.index)+s2_entr*len(subset_df2.index)\n",
    "        child_entr/=len(dfTemp.index)\n",
    "        tmpGain=parent_entr-child_entr\n",
    "        \n",
    "        if((best_gain==-np.inf and best_split==-np.inf)or(tmpGain>best_gain)):\n",
    "            best_split=split_point\n",
    "            best_gain=tmpGain\n",
    "        #print(split_point,tmpGain)\n",
    "    \n",
    "    return best_gain,best_split\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14470345494572923, -1.1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain_num(myFinalData,'emp.var.rate','y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self,attr_name,kind):\n",
    "        self.attr_name=attr_name\n",
    "        self.kind=kind\n",
    "    \n",
    "    def setThreshold(self,threshold):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.threshold=threshold\n",
    "        else:\n",
    "            raise ValueError(\"Threshold can't be set for categorical variable\")\n",
    "    \n",
    "    def setLessThanEq(self,cls):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.less_than_eq_class=cls\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for categorical variable\")\n",
    "    \n",
    "    def setGreaterThan(self,cls):\n",
    "        if(self.kind=='numeric'):\n",
    "            self.greater_than_class=cls\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for categorical variable\")\n",
    "    \n",
    "    def setLevelClassMap(self,levelClassMap):\n",
    "        if(self.kind=='categorical'):\n",
    "            self.levelClassMap=levelClassMap\n",
    "        else:\n",
    "            raise ValueError(\"Invalid for numeric variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isCategorical(df,attr):\n",
    "    if(df[attr].dtype.name=='category'):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "def DecisionStump(mydf,all_attr,target_attr,default_class=None):\n",
    "    df=mydf.copy(deep=True)\n",
    "    \n",
    "    gains=[] \n",
    "    for attr in all_attr:\n",
    "        if(isCategorical(df,attr)):\n",
    "            ig = information_gain_cat(df=df,split_attribute_name=attr,target_attribute_name=target_attr)\n",
    "            splt=-np.inf\n",
    "        else:\n",
    "            ig,splt=information_gain_num(df=df,split_attribute_name=attr,target_attribute_name=target_attr)\n",
    "        gains.append((ig,splt))\n",
    "        \n",
    "    mx_gain=max(gains,key=itemgetter(0))[0]\n",
    "    \n",
    "    #print(mx_gain)\n",
    "    \n",
    "    mx_gain_idx=-1\n",
    "    for i in range(len(gains)):\n",
    "        if(gains[i][0]==mx_gain):\n",
    "            mx_gain_idx=i\n",
    "            break\n",
    "#     print(gains)\n",
    "#     print(all_attr[mx_gain_idx])\n",
    "    \n",
    "    mx_gain_attr=all_attr[mx_gain_idx]\n",
    "    \n",
    "  #  print(mx_gain_attr)\n",
    "    \n",
    "    #splitting for Numeric Attributes\n",
    "    if(not(isCategorical(df,mx_gain_attr))):\n",
    "        thresh=gains[mx_gain_idx][1]\n",
    "        df1=df[df[mx_gain_attr]<=thresh]\n",
    "        df2=df[df[mx_gain_attr]>thresh]\n",
    "        dn=DecisionNode(mx_gain_attr,'numeric')\n",
    "        dn.setThreshold(thresh)\n",
    "        ly=df1[df1.y=='yes'].shape[0]\n",
    "        ln=df1[df1.y=='no'].shape[0]\n",
    "        \n",
    "        if(ly>=ln):\n",
    "            dn.setLessThanEq('yes')\n",
    "        else:\n",
    "            dn.setLessThanEq('no')\n",
    "        gy=df2[df2.y=='yes'].shape[0]\n",
    "        gn=df2[df2.y=='no'].shape[0]\n",
    "        if(gy>=gn):\n",
    "            dn.setGreaterThan('yes')\n",
    "        else:\n",
    "            dn.setGreaterThan('no')\n",
    "        \n",
    "        return dn\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        dn=DecisionNode(mx_gain_attr,'categorical')\n",
    "        df_split = df.groupby(mx_gain_attr)\n",
    "\n",
    "        dct={}\n",
    "        for name,group in df_split:\n",
    "            y=group[group.y=='yes'].shape[0]\n",
    "            n=group[group.y=='no'].shape[0]\n",
    "            if(y>=n):\n",
    "                dct[name]='yes'\n",
    "            else:\n",
    "                dct[name]='no'\n",
    "            #print(name,group[group.y=='yes'].shape[0],group[group.y=='no'].shape[0])\n",
    "            \n",
    "        print(dct)\n",
    "            #dct[name]=[entropy_list(np.array(group[target_attribute_name],dtype=pd.Series)),len(group)/nrows]\n",
    "        dn.setLevelClassMap(dct)\n",
    "        return dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(df,h):\n",
    "    attr=h.attr_name\n",
    "    dataPoints=df[attr]\n",
    "    y_pred=[]\n",
    "    if(h.kind=='categorical'):\n",
    "        dct=h.levelClassMap\n",
    "        y_pred= [dct[x] for x in dataPoints]\n",
    "    else:\n",
    "        thresh=h.threshold\n",
    "        for x in dataPoints:\n",
    "            if(x<=thresh):\n",
    "                y_pred.append(h.less_than_eq_class)\n",
    "            else:\n",
    "                y_pred.append(h.greater_than_class)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADABOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {yes,no}==>{+1,-1}\n",
    "\n",
    "class AdaBoost:\n",
    "    def __init__(self,k,target_attr):\n",
    "        self.hyp= []\n",
    "        self.hyp_wgt = []\n",
    "        self.k=k\n",
    "        self.target_attr=target_attr\n",
    "        \n",
    "    def train(self,df):\n",
    "        \n",
    "        sampN, _ = df.shape\n",
    "        samp_wgt = np.ones(sampN) / sampN\n",
    "        \n",
    "        ktmp=self.k\n",
    "        \n",
    "        \n",
    "        while ktmp>0:\n",
    "          #  print(samp_wgt)\n",
    "            \n",
    "            sampled_data=df.sample(n=sampN,replace=True,weights=samp_wgt)\n",
    "            cols=list(sampled_data.columns)\n",
    "            cols.remove(self.target_attr)\n",
    "            \n",
    "            h=DecisionStump(mydf=sampled_data,all_attr=cols,target_attr=self.target_attr)\n",
    "            \n",
    "            \n",
    "#             h = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "#             h.fit(X, y, sample_weight=samp_wgt)\n",
    "#             pred = h.predict(X)\n",
    "            \n",
    "            y_pred=Predict(df=sampled_data,h=h)\n",
    "            y_actual=np.array(sampled_data[self.target_attr],dtype=pd.Series)\n",
    "            \n",
    "            \n",
    "            yy_pred=[]\n",
    "            yy_actual=[]\n",
    "            \n",
    "            for i in range(len(y_actual)):\n",
    "                if(y_pred[i]=='yes'):\n",
    "                    yy_pred.append(1)\n",
    "                else:\n",
    "                    yy_pred.append(-1)\n",
    "                if(y_actual[i]=='yes'):\n",
    "                    yy_actual.append(1)\n",
    "                else:\n",
    "                    yy_actual.append(-1)\n",
    "    \n",
    "    \n",
    "            misses=[]\n",
    "            for i in range(len(yy_actual)):\n",
    "                if(yy_actual[i]!=yy_pred[i]):\n",
    "                    misses.append(np.float64(1))\n",
    "                else:\n",
    "                    misses.append(np.float64(0))\n",
    "        \n",
    "          #  print(misses)\n",
    "    \n",
    "            eps = np.dot(samp_wgt,misses)# samp_wgt.dot(yy_pred != yy_actual)\n",
    "            \n",
    "#             print(type(eps))\n",
    "#             print(eps)\n",
    "            \n",
    "            if(eps>0.5):\n",
    "                continue\n",
    "            \n",
    "            alpha = (np.log(1 - eps) - np.log(eps)) / 2.0\n",
    "            \n",
    "#             print(type(samp_wgt[0]))\n",
    "#             print(type(alpha))\n",
    "#             print(type(yy_actual))\n",
    "#             print(type(yy_pred))\n",
    "            \n",
    "            \n",
    "            yy_actual=np.array(yy_actual,dtype=np.float64)\n",
    "            yy_pred=np.array(yy_pred,dtype=np.float64)\n",
    "            \n",
    "            samp_wgt = samp_wgt * np.exp(- alpha * yy_actual * yy_pred)\n",
    "   #         print(\"after \",samp_wgt)\n",
    "\n",
    "\n",
    "#             for i in range(len(samp_wgt)):\n",
    "#               #  print(t, \" th samp_wgt \",samp_wgt[i])\n",
    "#                 if(math.isnan(samp_wgt[i])):\n",
    "#                     samp_wgt[i]=0\n",
    "            #print(max(samp_wgt))\n",
    "            #print(\"HELLOWORLD \",np.sum(samp_wgt))\n",
    "            samp_wgt = samp_wgt / samp_wgt.sum()\n",
    "            samp_wgt=np.array(samp_wgt,dtype=pd.Series)\n",
    "            #print(\"HELLOWORLD \",samp_wgt.sum())\n",
    "            \n",
    "#             print(t,\"th iteration\")\n",
    "#             print(samp_wgt)\n",
    "#             print(np.sum(samp_wgt,dtype=np.float128))\n",
    "#             print()\n",
    "            \n",
    "            self.hyp.append(h)\n",
    "            self.hyp_wgt.append(alpha)\n",
    "            ktmp-=1\n",
    "        return samp_wgt\n",
    "    \n",
    "    def test(self,X):\n",
    "        \n",
    "        sampN, _ = X.shape\n",
    "        samp_wgt = np.ones(sampN) / sampN\n",
    "        y=np.zeros(sampN)\n",
    "        \n",
    "        \n",
    "        for (h, alpha) in zip(self.hyp, self.hyp_wgt):\n",
    "            y_pred=Predict(df=X,h=h)\n",
    "            \n",
    "            yy_pred=[]\n",
    "            for i in range(len(y_pred)):\n",
    "                if(y_pred[i]=='yes'):\n",
    "                    yy_pred.append(np.float64(1))\n",
    "                else:\n",
    "                    yy_pred.append(np.float64(-1))\n",
    "            \n",
    "#             print(type(y))\n",
    "#             print(type(alpha))\n",
    "#             print(type(yy_pred))\n",
    "            yy_pred=np.array(yy_pred,dtype=np.float64)\n",
    "            \n",
    "            y = y + alpha * yy_pred\n",
    "        \n",
    "#         print(y)\n",
    "        \n",
    "        y = np.sign(y)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossValidation(df,target,k=3,K=5):\n",
    "    \n",
    "    \n",
    "    kf=KFold(n_splits=k,shuffle=True)\n",
    "    \n",
    "    models=[]\n",
    "    f1_scores=[]\n",
    "    \n",
    "    best_score=None\n",
    "    best_model=None\n",
    "    \n",
    "    \n",
    "    #print(kf.get_n_splits(df))\n",
    "    for train,test in kf.split(df):\n",
    "        \n",
    "        dftr=df.iloc[train]\n",
    "        dfts=df.iloc[test]\n",
    "        \n",
    "        ada=AdaBoost(k=K,target_attr=target)\n",
    "        \n",
    "        ada.train(df=dftr)\n",
    "        y_pred=ada.test(dfts)\n",
    "        y_true=np.array(dfts[target],dtype=pd.Series)\n",
    "        \n",
    "       # print(y_true)\n",
    "        \n",
    "        yy_true=[]\n",
    "        for i in range(len(y_true)):\n",
    "            if(y_true[i]=='yes'):\n",
    "                yy_true.append(1)\n",
    "            else:\n",
    "                yy_true.append(-1)\n",
    "                \n",
    "                \n",
    "        fs=f1_score(y_true=yy_true,y_pred=y_pred)\n",
    "        \n",
    "        models.append(ada)\n",
    "        f1_scores.append(fs)\n",
    "        \n",
    "        if(best_score==None or (fs>best_score)):\n",
    "            best_model=ada\n",
    "            best_score=fs\n",
    "        \n",
    "        print(fs)\n",
    "    \n",
    "    print(\"AVG: \",sum(f1_scores)/len(f1_scores))\n",
    "    \n",
    "    return best_model,best_score\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRYING fold =  5  and Round =  5\n",
      "\n",
      "0.6315789473684211\n",
      "0.6003937007874015\n",
      "0.6320582877959927\n",
      "0.6194368755676658\n",
      "0.6138059701492538\n",
      "AVG:  0.6194547563337469\n",
      "\n",
      "TRYING fold =  5  and Round =  10\n",
      "\n",
      "0.5949953660797034\n",
      "0.6220984215413184\n",
      "0.6452830188679246\n",
      "0.6283595922150138\n",
      "0.6087751371115173\n",
      "AVG:  0.6199023071630956\n",
      "\n",
      "TRYING fold =  5  and Round =  20\n",
      "\n",
      "0.613531047265987\n",
      "0.6116970278044104\n",
      "0.6123222748815165\n",
      "0.6606982990152194\n",
      "0.5990867579908675\n",
      "AVG:  0.6194670813916001\n",
      "\n",
      "TRYING fold =  10  and Round =  5\n",
      "\n",
      "0.5825242718446603\n",
      "0.6142595978062156\n",
      "0.6209523809523809\n",
      "0.6245353159851301\n",
      "0.6334519572953737\n",
      "0.6092184368737475\n",
      "0.6458333333333334\n",
      "0.6329113924050633\n",
      "0.6150943396226415\n",
      "0.6139705882352942\n",
      "AVG:  0.619275161435384\n",
      "\n",
      "TRYING fold =  10  and Round =  10\n",
      "\n",
      "0.6073500967117988\n",
      "0.5891472868217055\n",
      "0.6148148148148148\n",
      "0.624087591240876\n",
      "0.6564102564102564\n",
      "0.635036496350365\n",
      "0.6078799249530956\n",
      "0.6368715083798883\n",
      "0.6038461538461538\n",
      "0.6165137614678899\n",
      "AVG:  0.6191957890996844\n",
      "\n",
      "TRYING fold =  10  and Round =  20\n",
      "\n",
      "0.6421052631578948\n",
      "0.5988700564971751\n",
      "0.5973025048169556\n",
      "0.6019417475728156\n",
      "0.6206896551724138\n",
      "0.6297709923664122\n",
      "0.6052631578947368\n",
      "0.6223908918406071\n",
      "0.6539792387543253\n",
      "0.6199261992619927\n",
      "AVG:  0.6192239707335329\n",
      "\n",
      "TRYING fold =  20  and Round =  5\n",
      "\n",
      "0.6472727272727273\n",
      "0.6353790613718412\n",
      "0.5900383141762452\n",
      "0.6093189964157706\n",
      "0.6127946127946128\n",
      "0.6119402985074627\n",
      "0.6159695817490494\n",
      "0.6022304832713755\n",
      "0.5703422053231939\n",
      "0.6183206106870229\n",
      "0.6106870229007634\n",
      "0.648\n",
      "0.5845070422535211\n",
      "0.633204633204633\n",
      "0.6360424028268552\n",
      "0.6759581881533101\n",
      "0.6119402985074627\n",
      "0.6412213740458015\n",
      "0.6199261992619925\n",
      "0.6184738955823293\n",
      "AVG:  0.6196783974152986\n",
      "\n",
      "TRYING fold =  20  and Round =  10\n",
      "\n",
      "0.6385964912280702\n",
      "0.6456140350877193\n",
      "0.5498007968127491\n",
      "0.5606060606060607\n",
      "0.6124031007751938\n",
      "0.6083333333333333\n",
      "0.6520146520146521\n",
      "0.6567164179104478\n",
      "0.6691176470588235\n",
      "0.6428571428571429\n",
      "0.6153846153846154\n",
      "0.5952380952380952\n",
      "0.6219081272084807\n",
      "0.6409266409266409\n",
      "0.6109090909090908\n",
      "0.5985401459854014\n",
      "0.6564885496183206\n",
      "0.5839416058394161\n",
      "0.6293706293706294\n",
      "0.5972222222222222\n",
      "AVG:  0.6192994700193553\n",
      "\n",
      "TRYING fold =  20  and Round =  20\n",
      "\n",
      "0.6421404682274248\n",
      "0.701219512195122\n",
      "0.6413793103448275\n",
      "0.5494505494505494\n",
      "0.6324110671936758\n",
      "0.6446886446886447\n",
      "0.582089552238806\n",
      "0.7295597484276728\n",
      "0.7428571428571429\n",
      "0.627177700348432\n",
      "0.6188679245283019\n",
      "0.6312056737588653\n",
      "0.6315789473684211\n",
      "0.606060606060606\n",
      "0.6738351254480286\n",
      "0.6621160409556314\n",
      "0.5955882352941176\n",
      "0.5813953488372093\n",
      "0.628158844765343\n",
      "0.5327510917030568\n",
      "AVG:  0.6327265767345939\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try_fold=[5,10,20]\n",
    "try_round=[5,10,20]\n",
    "\n",
    "for i in try_fold:\n",
    "    for j in try_round:\n",
    "        print(\"TRYING fold = \",i,\" and Round = \",j)\n",
    "        print()\n",
    "        m,s=crossValidation(df=trainSet,k=i,K=j,target='y')\n",
    "        print()\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada=AdaBoost(k=10,target_attr='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0007103645837785005, 6.263883930184054e-05,\n",
       "       1.2711343094214027e-05, ..., 1.3374218659659362e-05,\n",
       "       0.00014261584313025159, 2.7900714377891153e-05], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada.train(df=trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=ada.test(X=testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6128482092097782"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_act=np.array(testSet['y'],dtype=pd.Series)\n",
    "yy_act=[]\n",
    "for i in range(len(y_act)):\n",
    "    if(y_act[i]=='yes'):\n",
    "        yy_act.append(1)\n",
    "    else:\n",
    "        yy_act.append(-1)\n",
    "\n",
    "f1_score(y_pred=y_pred,y_true=yy_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
